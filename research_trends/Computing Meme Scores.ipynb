{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "164b72b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ffcc49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "CACHE_PATH = '/scratch/datasets/mog29/unarXive'\n",
    "idf_path = os.path.join(CACHE_PATH, 'meme_idf.pkl')\n",
    "with open(idf_path, 'rb') as f:\n",
    "    meme_to_idf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7b376cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from combine_meme_files import get_combined_n_grams, get_combined_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ab44856",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 32/32 [00:15<00:00,  2.02it/s]\n"
     ]
    }
   ],
   "source": [
    "paper_to_metadata = get_combined_metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92272036",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 32/32 [19:51<00:00, 37.22s/it]\n"
     ]
    }
   ],
   "source": [
    "meme_to_articles = get_combined_n_grams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd17793e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from compute_meme_scores import compute_overall_frequencies, compute_n_gram_meme_score_terms, save_annual_meme_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5771a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = [i for i in range(1991, 2023)]\n",
    "year_to_frequencies = {year : {'num_papers' : 0, 'weighted_num_papers' : 0} for year in years}\n",
    "meme_to_score_components = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "279da358",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1881346/1881346 [00:01<00:00, 990635.28it/s]\n"
     ]
    }
   ],
   "source": [
    "compute_overall_frequencies(year_to_frequencies, paper_to_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5831aee6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 88908424/88908424 [14:21<00:00, 103191.33it/s]\n"
     ]
    }
   ],
   "source": [
    "compute_n_gram_meme_score_terms(meme_to_score_components, meme_to_articles, paper_to_metadata, meme_to_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d30d878",
   "metadata": {},
   "outputs": [],
   "source": [
    "meme_score_terms_path = os.path.join(CACHE_PATH, 'meme_score_terms.pkl')\n",
    "with open(meme_score_terms_path, 'wb') as f:\n",
    "    pickle.dump(meme_to_score_components, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b5a7ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c4b086c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 14494081/14494081 [03:37<00:00, 66664.29it/s]\n"
     ]
    }
   ],
   "source": [
    "meme_to_year_scores = {}\n",
    "for meme, meme_year_dict in tqdm(meme_to_score_components.items()):\n",
    "    meme_to_year_scores[meme] = {}\n",
    "    for curr_year, year_info in meme_year_dict.items():\n",
    "        # Compute the frequency scores                                                                                                                                                                                                                                                 \n",
    "        total_frequency = year_to_frequencies[curr_year]['num_papers']\n",
    "        meme_frequency = year_info['frequency']\n",
    "        frequency_score = meme_frequency / total_frequency\n",
    "        weighted_total_frequency = year_to_frequencies[curr_year]['weighted_num_papers']\n",
    "        weighted_meme_frequency = year_info['weighted_frequency']\n",
    "        weighted_frequency_score = weighted_meme_frequency / weighted_total_frequency\n",
    "\n",
    "        # Compute sticking scores                                                                                                                                                                                                                                                      \n",
    "        in_paper_in_citations = year_info['in_paper_in_citations']\n",
    "        in_citations = year_info['in_citations']\n",
    "        sticking_score = in_paper_in_citations / (3 + in_citations)\n",
    "        weighted_in_paper_in_citations = year_info['weighted_in_paper_in_citations']\n",
    "        weighted_in_citations = year_info['weighted_in_citations']\n",
    "        weighted_sticking_score = weighted_in_paper_in_citations / (3 + weighted_in_citations)\n",
    "\n",
    "        # Compute sparking scores                                                                                                                                                                                                                                                      \n",
    "        in_paper_not_in_citations = year_info['in_paper_not_in_citations']\n",
    "        not_in_citations = year_info['not_in_citations']\n",
    "        sparking_score = (3+in_paper_not_in_citations) / (3 + not_in_citations)\n",
    "        weighted_in_paper_not_in_citations = year_info['weighted_in_paper_not_in_citations']\n",
    "        weighted_not_in_citations = year_info['weighted_not_in_citations']\n",
    "        weighted_sparking_score = (3+weighted_in_paper_not_in_citations) / (3 + weighted_not_in_citations)\n",
    "\n",
    "        # Compute meme scores                                                                                                                                                                                                                                                          \n",
    "        meme_score = frequency_score * sticking_score / sparking_score\n",
    "        weighted_meme_score = weighted_frequency_score * weighted_sticking_score / weighted_sparking_score\n",
    "        meme_to_year_scores[meme][curr_year] = {\n",
    "            \"meme_score\" : meme_score,\n",
    "            \"weighted_meme_score\" : weighted_meme_score\n",
    "        }\n",
    "\n",
    "meme_score_path = os.path.join(CACHE_PATH, 'meme_scores.pkl')\n",
    "with open(meme_score_path, 'wb') as f:\n",
    "    pickle.dump(meme_to_year_scores, f)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c1048909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial qualitative analysis of the results\n",
    "def get_sorted_meme_scores_for_year(meme_scores, year):\n",
    "    meme_score_pairs = []\n",
    "    weighted_meme_score_pairs = []\n",
    "    for meme, year_dicts in tqdm(meme_scores.items()):\n",
    "        if year not in year_dicts:\n",
    "            continue\n",
    "            \n",
    "        curr_scores = year_dicts[year]\n",
    "        meme_score_pairs.append((meme, curr_scores['meme_score']))\n",
    "        weighted_meme_score_pairs.append((meme, curr_scores['weighted_meme_score']))\n",
    "        \n",
    "    meme_score_pairs = sorted(meme_score_pairs, reverse=True, key=lambda x: x[1])\n",
    "    weighted_meme_score_pairs = sorted(weighted_meme_score_pairs, reverse=True, key=lambda x: x[1])\n",
    "    \n",
    "    return meme_score_pairs, weighted_meme_score_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2b324b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 14494081/14494081 [00:15<00:00, 908364.39it/s]\n"
     ]
    }
   ],
   "source": [
    "meme_score, weighted_meme_score = get_sorted_meme_scores_for_year(meme_to_year_scores, 2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d95ccc63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained 0.1773641118589446\n",
      "learn 0.16598443555810838\n",
      "neural networks 0.16518028844999447\n",
      "stateoftheart 0.1548679215546893\n",
      "architecture 0.14387493651586314\n",
      "neural network 0.1331927030825037\n",
      "machine learning 0.1240704648977611\n",
      "language 0.12256257281467631\n",
      "deep learning 0.11123663655511944\n",
      "the training 0.11087881975606667\n",
      "train 0.11015153909430844\n",
      "we propose a 0.10666087363209233\n",
      "human 0.10580723548133623\n",
      "a novel 0.10031859363454211\n",
      "to learn 0.09895728689589807\n",
      "inference 0.09865282298354792\n",
      "our method 0.09800538070376905\n",
      "performance of 0.09290599681119366\n",
      "learned 0.09284015150305906\n",
      "the input 0.09219680758046873\n",
      "improve 0.09159292031201619\n",
      "recognition 0.09157715283152487\n",
      "evaluation 0.09125910053534302\n",
      "attention 0.0910063138371464\n",
      "text 0.08827277072991527\n",
      "labels 0.08629191359653055\n",
      "quality 0.08235825204215229\n",
      "processing 0.08053670415372756\n",
      "training data 0.0801298211831231\n",
      "prior 0.07987070658310638\n",
      "uses 0.07971238852510326\n",
      "the network 0.07935667688887404\n",
      "challenging 0.07900048660714747\n",
      "visual 0.07807184999985987\n",
      "weights 0.07767208027730291\n",
      "convolutional 0.07664016700571413\n",
      "our approach 0.07566736787448446\n",
      "semantic 0.07519672171101155\n",
      "objective 0.07360950856149148\n",
      "embedding 0.0722608053601514\n",
      "the best 0.07064116756933367\n",
      "segmentation 0.06965623597415498\n",
      "classifier 0.06879863573551093\n",
      "words 0.06854097785499205\n",
      "regression 0.06841442791739846\n",
      "label 0.06838969762417133\n",
      "architectures 0.06835638559428331\n",
      "robust 0.0681075811439656\n",
      "evaluate 0.06799394338918674\n",
      "cnn 0.06765508581999749\n",
      "vision 0.06703641029809022\n",
      "settings 0.06698961729492002\n",
      "3d 0.06616447476253039\n",
      "the performance 0.06488917722211059\n",
      "predict 0.06477082217963247\n",
      "our model 0.06404789171833923\n",
      "pretrained 0.0638500946086032\n",
      "to generate 0.06373055969611584\n",
      "challenges 0.06361404450627171\n",
      "the performance of 0.06328169793547858\n",
      "sampling 0.06283822837665318\n",
      "adversarial 0.06263595276513073\n",
      "users 0.062489611874751806\n",
      "latent 0.061156090275318625\n",
      "model to 0.06097452884730592\n",
      "baseline 0.06072725807894041\n",
      "realworld 0.060663625959147864\n",
      "user 0.06062517666109637\n",
      "score 0.060485657454037056\n",
      "encoder 0.060113458484081915\n",
      "module 0.05968251199540534\n",
      "domains 0.05964390593936403\n",
      "address 0.05942977724879791\n",
      "machine 0.05938876793201176\n",
      "word 0.059135887889040145\n",
      "capture 0.05858985296153339\n",
      "embeddings 0.0584157761115989\n",
      "challenge 0.05802565867150359\n",
      "memory 0.05796132175295345\n",
      "this work we 0.05780826011676662\n",
      "that can 0.056495738626036816\n",
      "summarized as follows 0.05647355122408341\n",
      "focus on 0.055791252235447564\n",
      "used for 0.055746286240980616\n",
      "video 0.055619216036918946\n",
      "in this work we 0.055278644639169684\n",
      "supervised 0.05503332129006592\n",
      "reinforcement learning 0.05458468652901262\n",
      "goal 0.05450119409457094\n",
      "data and 0.05429757929493422\n",
      "similarity 0.05396838972364762\n",
      "selection 0.053255769421785504\n",
      "the image 0.05320476569651231\n",
      "inputs 0.05309245778760703\n",
      "policy 0.0527702896508289\n",
      "online 0.052691789517250544\n",
      "achieves 0.052360589075775794\n",
      "of data 0.05217476350667587\n",
      "generative 0.051980334220638136\n",
      "proposed method 0.051963416925948136\n"
     ]
    }
   ],
   "source": [
    "for meme, score in meme_score[:100]:\n",
    "    print(meme, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e5b9dd01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained 0.1810522361894\n",
      "learn 0.16803750218735414\n",
      "neural networks 0.1672987904513681\n",
      "stateoftheart 0.15752213537776938\n",
      "architecture 0.14665979525444198\n",
      "neural network 0.1348350275379179\n",
      "machine learning 0.1254334265737546\n",
      "language 0.1231812482385631\n",
      "deep learning 0.11348443138850736\n",
      "the training 0.11295072270276416\n",
      "train 0.11244076260788748\n",
      "we propose a 0.10867881388305103\n",
      "human 0.10670393011344359\n",
      "a novel 0.10229004628842434\n",
      "to learn 0.10022245873726071\n",
      "our method 0.09971765489410662\n",
      "inference 0.09905207832842905\n",
      "performance of 0.09420467081678638\n",
      "improve 0.09360692336798379\n",
      "learned 0.09353560487798242\n",
      "the input 0.09347454301353736\n",
      "attention 0.09336471492914196\n",
      "evaluation 0.09246951694732855\n",
      "recognition 0.09102087819100287\n",
      "text 0.0890931628935262\n",
      "labels 0.08741792491515536\n",
      "quality 0.08368288468380995\n",
      "training data 0.08102298354052631\n",
      "challenging 0.08032964937065402\n",
      "processing 0.08024994448734463\n",
      "prior 0.08021128642837637\n",
      "uses 0.08021076255500915\n",
      "the network 0.07980687218860455\n",
      "visual 0.07873599775650919\n",
      "weights 0.0781465948736322\n",
      "convolutional 0.07706967027749127\n",
      "our approach 0.07571286546202186\n",
      "semantic 0.07560737143100671\n",
      "objective 0.07407737116300694\n",
      "embedding 0.07348815583097608\n",
      "the best 0.07083248729595727\n",
      "segmentation 0.07044858494657079\n",
      "architectures 0.06965404380249085\n",
      "label 0.06911672561677538\n",
      "evaluate 0.06907845026007474\n",
      "robust 0.06878219245701488\n",
      "classifier 0.06870957218045624\n",
      "settings 0.06818006378925769\n",
      "cnn 0.06791980947610916\n",
      "regression 0.06784799831371809\n",
      "vision 0.06762437396669158\n",
      "3d 0.06731124154145629\n",
      "words 0.06710972467853711\n",
      "pretrained 0.06661939668283355\n",
      "the performance 0.06623210273706684\n",
      "predict 0.06576518897863502\n",
      "to generate 0.06517239005881281\n",
      "challenges 0.06510746555997839\n",
      "our model 0.06449795568250946\n",
      "the performance of 0.0641782999612796\n",
      "adversarial 0.06406490848732108\n",
      "sampling 0.06302955117020362\n",
      "users 0.06297074557716965\n",
      "model to 0.06242151701330398\n",
      "encoder 0.06221709100050802\n",
      "realworld 0.06221324741780106\n",
      "baseline 0.06205571437361568\n",
      "module 0.061891934829410675\n",
      "latent 0.06152439893301311\n",
      "score 0.06135866762612757\n",
      "user 0.06073565255519876\n",
      "address 0.060413052980072136\n",
      "domains 0.06023049196761221\n",
      "embeddings 0.05962370089596489\n",
      "capture 0.059229022982932596\n",
      "machine 0.059167125807165606\n",
      "challenge 0.05904715774700594\n",
      "this work we 0.05898820134184447\n",
      "summarized as follows 0.05848781319947301\n",
      "memory 0.05830646989260928\n",
      "word 0.05803999909448271\n",
      "that can 0.0571392983152633\n",
      "focus on 0.05674640112370829\n",
      "in this work we 0.05641718869266322\n",
      "video 0.05606329544129922\n",
      "used for 0.055935892989941983\n",
      "supervised 0.05571349063309647\n",
      "reinforcement learning 0.05560274450599342\n",
      "data and 0.05502107427741062\n",
      "goal 0.05449156496930578\n",
      "similarity 0.05396452875333772\n",
      "inputs 0.0539640732450024\n",
      "achieves 0.053743206570294674\n",
      "policy 0.053606227483807264\n",
      "the image 0.053198447130227575\n",
      "metrics 0.052882708606138466\n",
      "generative 0.05265055288982354\n",
      "proposed method 0.05263444703178465\n",
      "online 0.05258817244975681\n",
      "selection 0.05254497009223452\n"
     ]
    }
   ],
   "source": [
    "for meme, score in weighted_meme_score[:100]:\n",
    "    print(meme, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec937a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
