{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1683ff83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90ee7be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "data = {}\n",
    "base_folder = '/scratch/datasets/mog29/unarXive'\n",
    "filenames = ['paper_to_section_metadata_0_23.pkl', 'paper_to_section_metadata_23_29.pkl',\n",
    "            'paper_to_section_metadata_29_32.pkl']\n",
    "\n",
    "for filename in filenames:\n",
    "    with open(os.path.join(base_folder, filename), 'rb') as f:\n",
    "        curr_data = pickle.load(f)\n",
    "    for key, val in curr_data.items():\n",
    "        data[key] = val\n",
    "\n",
    "VALID_DISCIPLINES = [\"cs.AI\", \"cs.CL\", \"cs.CV\", \"cs.LG\", \"stat.ML\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14f9ab87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def process_section_name(input_text):\n",
    "    lowercase_text = input_text.lower()\n",
    "    replaced_text = lowercase_text.replace('\\n', ' ')\n",
    "    return replaced_text\n",
    "\n",
    "def get_most_common_section_names(data, category_list):\n",
    "    name_to_count = Counter()\n",
    "    num_to_count = Counter()\n",
    "    for _, metadata_dict in data.items():\n",
    "        # Choose whether to filter the paper\n",
    "        if category_list is not None:\n",
    "            paper_cats = metadata_dict['categories']\n",
    "            found_match = any([cat in category_list for cat in paper_cats])\n",
    "            if not found_match:\n",
    "                continue\n",
    "        \n",
    "        section_name_set = set()\n",
    "        section_num_set = set()\n",
    "        for section_name, section_num in metadata_dict['name_number_pairs']:\n",
    "            if section_name is None or section_num is None:\n",
    "                continue\n",
    "\n",
    "            proc_section_name = process_section_name(section_name)\n",
    "            section_name_set.add(proc_section_name)\n",
    "            section_num_set.add(section_num)\n",
    "\n",
    "        for section_name in section_name_set:\n",
    "            name_to_count[section_name] += 1\n",
    "        for section_num in section_num_set:\n",
    "            num_to_count[section_num] += 1\n",
    "            \n",
    "    return name_to_count, num_to_count\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e3544210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' ']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".split('.')[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3928df84",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('introduction', 200458), ('conclusion', 104881), ('related work', 75358), ('experiments', 50217), ('conclusions', 31980), ('results', 31037), ('acknowledgements', 28743), ('discussion', 26693), ('acknowledgments', 26122), ('datasets', 18744), ('implementation details', 18024), ('experimental setup', 14077), ('experimental results', 13574), ('ablation study', 13368), ('method', 12761), ('methodology', 12373), ('acknowledgment', 11671), ('preliminaries', 11226), ('dataset', 11015), ('conclusion and future work', 10680), ('background', 10552), ('acknowledgement', 9782), ('related works', 9780), ('evaluation', 9343), ('problem formulation', 8181), ('evaluation metrics', 7823), ('methods', 7462), ('baselines', 6751), ('training', 6027), ('data', 5986), ('overview', 5891), ('conclusions and future work', 5808), ('proof of theorem ', 5562), ('results and discussion', 5470), ('proposed method', 5068), ('proof of theorem\\xa0', 4889), ('ablation studies', 4811), ('implementation', 4560), ('main results', 4522), ('experiments and results', 4402), ('approach', 4335), ('appendix', 4330), ('limitations', 4251), ('analysis', 4194), ('contributions', 4170), ('notation', 4144), ('network architecture', 4073), ('experimental settings', 4029), ('training details', 3883), ('model', 3824), ('motivation', 3612), ('experiment', 3521), ('problem statement', 3468), ('problem definition', 3438), ('setup', 3386), ('loss function', 3222), ('qualitative results', 3144), ('proof of lemma ', 3142), ('discussion and conclusion', 3129), ('metrics', 3049), ('numerical experiments', 2921), ('algorithm', 2904), ('future work', 2851), ('experimental evaluation', 2850), ('proof of lemma\\xa0', 2810), ('architecture', 2711), ('summary', 2697), ('models', 2653), ('model architecture', 2517), ('proofs', 2431), ('experiment setup', 2379), ('optimization', 2285), ('hyperparameters', 2285), ('concluding remarks', 2281), ('case study', 2239), ('notations', 2168), ('broader impact', 2153), ('data collection', 2036), ('results and analysis', 2024), ('proposed approach', 1996)]\n"
     ]
    }
   ],
   "source": [
    "name_to_count, num_to_count = get_most_common_section_names(data, VALID_DISCIPLINES)\n",
    "sorted_name_to_count = sorted(list(name_to_count.items()), reverse=True, key=lambda x: x[1])\n",
    "print(sorted_name_to_count[:80])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f955fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_common_parent_section_names(data, category_list):\n",
    "    name_to_count = Counter()\n",
    "    for _, metadata_dict in data.items():\n",
    "        # Choose whether to filter the paper\n",
    "        if category_list is not None:\n",
    "            paper_cats = metadata_dict['categories']\n",
    "            found_match = any([cat in category_list for cat in paper_cats])\n",
    "            if not found_match:\n",
    "                continue\n",
    "        \n",
    "        section_name_set = set()\n",
    "        for section_name, section_num in metadata_dict['name_number_pairs']:\n",
    "            if section_name is None or section_num is None:\n",
    "                continue\n",
    "                \n",
    "            section_subsection = section_num.split('.')\n",
    "            singleton = len(section_subsection) == 1\n",
    "            hidden_singleton = len(section_subsection) == 2 and section_subsection[1] == ''\n",
    "            if not (singleton or hidden_singleton):\n",
    "                continue\n",
    "                \n",
    "            proc_section_name = process_section_name(section_name)\n",
    "            section_name_set.add(proc_section_name)\n",
    "\n",
    "        for section_name in section_name_set:\n",
    "            name_to_count[section_name] += 1\n",
    "            \n",
    "    return name_to_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a35f2ef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('introduction', 200375), ('conclusion', 104428), ('related work', 70740), ('experiments', 49311), ('conclusions', 31828), ('acknowledgements', 28067), ('acknowledgments', 25659), ('discussion', 24018), ('results', 21436), ('method', 12401), ('methodology', 11872), ('acknowledgment', 11604), ('experimental results', 11526), ('conclusion and future work', 10647), ('implementation details', 9816), ('datasets', 9742), ('background', 9674), ('acknowledgement', 9578), ('preliminaries', 9476), ('related works', 9040), ('experimental setup', 8583), ('evaluation', 7002), ('methods', 6950), ('dataset', 6521), ('ablation study', 6285), ('problem formulation', 6183), ('conclusions and future work', 5789), ('proposed method', 4927), ('results and discussion', 4578), ('evaluation metrics', 4446), ('appendix', 4327), ('experiments and results', 4311), ('approach', 4156), ('overview', 3572), ('data', 3428), ('experiment', 3413), ('discussion and conclusion', 3121), ('limitations', 3069), ('proof of theorem ', 3064), ('implementation', 2827), ('numerical experiments', 2815), ('experimental evaluation', 2789), ('problem statement', 2688), ('training', 2666), ('proof of theorem\\xa0', 2663), ('model', 2660), ('baselines', 2574), ('analysis', 2563), ('network architecture', 2465), ('ablation studies', 2405), ('motivation', 2377), ('problem definition', 2356), ('future work', 2299), ('concluding remarks', 2242), ('contributions', 2240), ('proofs', 2213), ('main results', 2175), ('summary', 2092), ('broader impact', 2062), ('experimental settings', 2051), ('proposed approach', 1896), ('notation', 1882), ('training details', 1860), ('algorithm', 1858), ('loss function', 1842), ('qualitative results', 1735), ('numerical results', 1732), ('applications', 1655), ('discussion and future work', 1643), ('background and related work', 1626), ('our approach', 1582), ('metrics', 1491), ('proof of lemma ', 1474), ('conclusion and discussion', 1447), ('architecture', 1421), ('results and analysis', 1318), ('data collection', 1313), ('discussions', 1312), ('experiment setup', 1294), ('proof of lemma\\xa0', 1288)]\n"
     ]
    }
   ],
   "source": [
    "name_to_count = get_most_common_parent_section_names(data, VALID_DISCIPLINES)\n",
    "sorted_name_to_count = sorted(list(name_to_count.items()), reverse=True, key=lambda x: x[1])\n",
    "print(sorted_name_to_count[:80])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "73e2310a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_common_section_after(data, target_name, category_list):\n",
    "    name_to_count = Counter()\n",
    "    for _, metadata_dict in data.items():\n",
    "        # Choose whether to filter the paper\n",
    "        if category_list is not None:\n",
    "            paper_cats = metadata_dict['categories']\n",
    "            found_match = any([cat in category_list for cat in paper_cats])\n",
    "            if not found_match:\n",
    "                continue\n",
    "        \n",
    "        all_pairs = sorted(list(set(metadata_dict['name_number_pairs'])), key=lambda x: x[1])\n",
    "\n",
    "        section_idx = -1\n",
    "        curr_val = -1\n",
    "        for curr_name, curr_num in all_pairs:\n",
    "            curr_val += 1\n",
    "            if curr_name is None: \n",
    "                continue\n",
    "\n",
    "            proc_curr_name = process_section_name(curr_name)\n",
    "\n",
    "            if target_name in proc_curr_name:\n",
    "                section_idx = curr_val\n",
    "                break\n",
    "                \n",
    "        if section_idx != -1 and section_idx != len(all_pairs) - 1:\n",
    "            next_section = all_pairs[section_idx + 1][0]\n",
    "            if next_section is None:\n",
    "                continue\n",
    "            \n",
    "            proc_section_name = process_section_name(next_section)\n",
    "            name_to_count[proc_section_name] += 1\n",
    "            \n",
    "    return name_to_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4653414a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('a simple example', 1), ('programming languages as analogues, not metaphors', 1), ('ambiguity resolution', 1), ('overview of compere', 1), ('abstraction and focus', 1), ('extending the clustering algorithm to {{formula:738dbf0c-1e0c-4154-be09-3fc7e02b91e0}} -grams', 1), ('a family of categorial calculi and their linguistic applications', 1), ('relating project internal and comparative assessment', 1), ('the knowledge grapher', 1), ('test data maintenance and retrieval', 1), ('an overview of the thesis', 1), ('the linguistic data', 1), ('code format', 1), ('adaptive clustering', 1), ('the grammar (set)', 1), ('the problem', 1), ('two-layered architecture', 1), ('relations between discourse segments', 1), ('optimality theory', 1), ('purpose factors', 1), ('shallow parsers with hand-written rules', 1), ('a time-local index', 1), ('linear combining of biased classifiers', 1), ('results', 1), ('the corresponding decision problems', 1), ('distributed artificial intelligence', 1), ('formal description of the system', 1), ('algorithm', 1), ('boolean constraints', 1), ('semantics:', 1), ('grammar checking', 1), ('bagging for parsing', 1), ('index subsorts', 1), ('acknowledgments', 1), ('annotation graphs', 1)]\n"
     ]
    }
   ],
   "source": [
    "name_to_count = get_most_common_section_after(data, 'background', VALID_DISCIPLINES)\n",
    "sorted_name_to_count = sorted(list(name_to_count.items()), reverse=True, key=lambda x: x[1])\n",
    "print(sorted_name_to_count[:40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "746601aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = list(data.keys())\n",
    "num_keys = len(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4607d7ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f7d1f211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paper categories: ['quant-ph']\n",
      "Paper section names: {('Adiabatic-transfer state', '2'), ('Late-time eigenvalues', '2'), ('The case of vanishing {{formula:ebdacfec-a5be-4f37-b322-8d5813f7687b}}  and {{formula:b0bd1f31-ebbc-448f-b495-37596914250a}}', '4'), ('Examples', '3'), ('Condition for a zero eigenvalue', '1'), ('Connectivity', '3'), ('Basic STIRAP', '1'), ('Arbitrary couplings', '3'), ('Arbitrary couplings', '2'), ('Proportional couplings', '2'), ('Proportional couplings', '1'), ('Introduction', '1'), ('Early-time eigenvalues', '1'), ('Nonzero eigenvalue', '2'), ('Acknowledgments', '-1'), ('The system', '1'), ('The case of vanishing {{formula:bacdc82a-fee2-4e90-89bb-d1603170b333}} , {{formula:1de67265-7c47-4d9f-bd12-b4d84c8638c1}} , and {{formula:24dea737-caf3-45b7-970c-33e3e5b1e5f9}}', '4'), ('The off-resonance case', '1'), ('Discussion and conclusions', '7'), ('The off-resonance case', '3'), ('Connectivity and AT condition', '3'), ('Degenerate resonant intermediate states', '5'), ('The on-resonance case', '2'), ('Examples', '5'), ('No zero eigenvalue', '2'), ('A zero eigenvalue', '1')}\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random_paper = keys[random.randint(0, num_keys-1)]\n",
    "print(f\"Paper categories: {data[random_paper]['categories']}\")\n",
    "print(f\"Paper section names: {set(data[random_paper]['name_number_pairs'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3f84f39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "VALID_DISCIPLINES = [\"cs.AI\", \"cs.CL\", \"cs.CV\", \"cs.LG\", \"stat.ML\"]\n",
    "ml_papers = []\n",
    "for key, metadata_dict in data.items():\n",
    "    paper_cats = metadata_dict['categories']\n",
    "    found_match = any([cat in VALID_DISCIPLINES for cat in paper_cats])\n",
    "    if found_match:\n",
    "        ml_papers.append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "64d4e4a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paper categories: ['cs.CL']\n",
      "Paper section names: {('A Compact Architecture for Dialogue Management Based on Scripts\\nand Meta-Outputs', '4'), ('Using meta-outputs to choose between dialogue management moves', '4.3'), ('Fallible Interpretation: Outputs and Meta-outputs', '2.2'), ('Examples', '5'), ('Summary', '6'), ('A Prototype Implementation', '3'), ('Integration of plan evaluation, plan execution and dialogue management', '4.1'), ('Using meta-outputs to choose between interpretations', '4.2'), ('Scripts vs Logical Forms', '2.1'), ('How Meta-outputs Participate in the Translation', '3.2'), ('Levels of Representation', '3.1'), ('Introduction', '1')}\n"
     ]
    }
   ],
   "source": [
    "num_ml_papers = len(ml_papers)\n",
    "random_paper = ml_papers[random.randint(0, num_ml_papers-1)]\n",
    "print(f\"Paper categories: {data[random_paper]['categories']}\")\n",
    "print(f\"Paper section names: {set(data[random_paper]['name_number_pairs'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6d8b6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
